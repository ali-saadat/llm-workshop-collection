{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "🚀 LLM Workshop: Part 1 - Setup and LLM Hello World\n",
    "Duration: ~45 minutes\n",
    "Level: Beginner\n",
    "\n",
    "IMPORTANT: Make sure your virtual environment is activated!\n",
    "If you haven't set up the environment yet, run: python3 workshop_setup.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c8296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acf94a9",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "🔧 SECTION 1: SETUP AND CONFIGURATION\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎯 LLM WORKSHOP - PART 1: Setup and LLM Hello World\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b93bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c62df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = os.getenv(\"BASE_URL\", \"https://yylh5vmmm0.execute-api.eu-central-1.amazonaws.com/prod/v1\")\n",
    "API_KEY = os.getenv(\"API_KEY\", \"ALI-CLASS-2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9c68bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers for authentication\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0578b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Configuration loaded!\")\n",
    "print(f\"🌐 Base URL: {BASE_URL}\")\n",
    "print(f\"🔑 API Key: {API_KEY[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092edae",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "🧪 TEST 1: Check Available Models\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d920488",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🧪 TEST 1: Check Available Models\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0552f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def check_models():\n",
    "    \"\"\"Check what models are available on your endpoint\"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"{BASE_URL}/v1/models\", headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            models = response.json()\n",
    "            print(\"✅ Successfully connected to your endpoint!\")\n",
    "            print(\"📋 Available models:\")\n",
    "            for model in models.get('data', []):\n",
    "                print(f\"   - {model.get('id', 'Unknown')}\")\n",
    "            return models\n",
    "        else:\n",
    "            print(f\"❌ Error: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Connection error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c18b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the connection\n",
    "models = check_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca578489",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "🌟 LLM HELLO WORLD: Basic Text Generation\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b79d37",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🌟 LLM HELLO WORLD: Basic Text Generation\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89aa766",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_text(prompt: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    \"\"\"Generate text using your LLM endpoint\"\"\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 150,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{BASE_URL}/v1/chat/completions\", \n",
    "                               headers=headers, \n",
    "                               json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Exception: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Simple greeting\n",
    "print(\"🤖 Test 1: Simple Greeting\")\n",
    "prompt1 = \"Hello! Can you give me a friendly greeting in 2 sentences?\"\n",
    "response1 = generate_text(prompt1)\n",
    "print(f\"Prompt: {prompt1}\")\n",
    "print(f\"Response: {response1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Creative writing\n",
    "print(\"\\n🤖 Test 2: Creative Writing\")\n",
    "prompt2 = \"Write a short, fun story about a robot learning to cook (max 3 sentences)\"\n",
    "response2 = generate_text(prompt2)\n",
    "print(f\"Prompt: {prompt2}\")\n",
    "print(f\"Response: {response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424f71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Code explanation\n",
    "print(\"\\n🤖 Test 3: Code Explanation\")\n",
    "prompt3 = \"Explain what a Python function is in simple terms (max 2 sentences)\"\n",
    "response3 = generate_text(prompt3)\n",
    "print(f\"Prompt: {prompt3}\")\n",
    "print(f\"Response: {response3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605446c0",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "🔄 LLM HELLO WORLD: Chat Completion\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f12ec",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔄 LLM HELLO WORLD: Chat Completion\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd47b89c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def chat_completion(messages: list, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    \"\"\"Have a conversation with your LLM\"\"\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{BASE_URL}/v1/chat/completions\", \n",
    "                               headers=headers, \n",
    "                               json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return f\"Error: {response.status_code} - {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Exception: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a conversation\n",
    "print(\"💬 Starting a conversation...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi! I'm learning about LLMs. Can you help me?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First response\n",
    "response = chat_completion(conversation)\n",
    "print(f\"🤖 Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1743109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to conversation and continue\n",
    "conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "conversation.append({\"role\": \"user\", \"content\": \"What's the most exciting thing about LLMs?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f12ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = chat_completion(conversation)\n",
    "print(f\"🤖 Assistant: {response2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8f2f4",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "🎯 HANDS-ON EXERCISE\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🎯 HANDS-ON EXERCISE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5173aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "🎯 Your Turn! Try these exercises:\n",
    "\n",
    "1. **Custom Prompt**: Create your own prompt and see what the LLM generates\n",
    "   - Try asking about your favorite hobby\n",
    "   - Ask for a recipe or travel tip\n",
    "   - Request a poem or joke\n",
    "\n",
    "2. **Temperature Experiment**: Change the temperature value (0.1 to 1.0)\n",
    "   - Lower = more focused/consistent\n",
    "   - Higher = more creative/varied\n",
    "\n",
    "3. **Token Limit**: Experiment with max_tokens\n",
    "   - Try 50, 100, 200 tokens\n",
    "   - See how it affects response length\n",
    "\n",
    "4. **Model Comparison**: If you have multiple models, compare their outputs\n",
    "\n",
    "💡 Tips:\n",
    "- Keep prompts clear and specific\n",
    "- Start with simple requests\n",
    "- Don't worry about perfect responses - this is learning!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb2f34",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "📝 SUMMARY\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab95cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📝 PART 1 SUMMARY\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c19120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "✅ What We Accomplished:\n",
    "- Connected to your LLM endpoint\n",
    "- Checked available models\n",
    "- Generated text with simple prompts\n",
    "- Had a conversation with the LLM\n",
    "- Learned about temperature and tokens\n",
    "\n",
    "🔑 Key Concepts:\n",
    "- API endpoints and authentication\n",
    "- Text generation vs chat completion\n",
    "- Prompt engineering basics\n",
    "- Model parameters (temperature, max_tokens)\n",
    "\n",
    "🚀 Next Up: LLM Agents with LangChain!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062917b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎉 Part 1 Complete! Ready for Part 2: LLM Agents?\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
